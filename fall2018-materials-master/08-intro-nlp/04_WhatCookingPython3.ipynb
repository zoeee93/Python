{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's Cooking  in Python\n",
    "https://www.kaggle.com/manuelatadvice/whats-cooking/noname/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You might need to install this. \n",
    "#!conda install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This imports a bunch of packages.  \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "import json\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn import grid_search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#If you import the codes locally, this seems to cause some issues.  \n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "\n",
    "urltrain= 'https://raw.githubusercontent.com/RPI-Analytics/MGMT6963-2015/master/data/whatscooking/whatscookingtrain.json'\n",
    "urltest = 'https://raw.githubusercontent.com/RPI-Analytics/MGMT6963-2015/master/data/whatscooking/whatscookingtest.json'\n",
    "\n",
    "\n",
    "train = pd.read_json(urlopen(urltrain))\n",
    "test = pd.read_json(urlopen(urltest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we want to see the most popular cuisine for the naive model. \n",
    "train.groupby('cuisine').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we write the most popular selection.  This is the baseline by which we will judge other models. \n",
    "test['cuisine']='italian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THis is a much more simple version that selects out the columns ID and cuisinte\n",
    "submission=test[['id' ,  'cuisine' ]]\n",
    "#This is a more complex method I showed that gives same.\n",
    "#submission=pd.DataFrame(test.ix[:,['id' ,  'cuisine' ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This outputs the file.\n",
    "submission.to_csv(\"1_cookingSubmission.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So it seems there is some data we need to use the NLTK leemmatizer.  \n",
    "stemmer = WordNetLemmatizer()\n",
    "nltk.download('wordnet')\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We see this in a Python Solution. \n",
    "train['ingredients_clean_string1'] = [','.join(z).strip() for z in train['ingredients']] \n",
    "\n",
    "#We also know that we can do something similar though a Lambda function. \n",
    "strip = lambda x: ' , '.join(x).strip() \n",
    "#Finally, we call the function for name\n",
    "train['ingredients_clean_string2'] = train['ingredients'].map(strip)\n",
    "\n",
    "#Now that we used the lambda function, we can reuse this for the test dataset. \n",
    "test['ingredients_clean_string1'] = test['ingredients'].map(strip)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We see this in one of the solutions.  We can reconstruct it in a way that makes it abit easier to follow, but I found when doing that it took forever.  \n",
    "\n",
    "#To interpret this, read from right to left. \n",
    "train['ingredients_string1'] = [' '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in train['ingredients']]       \n",
    "test['ingredients_string1'] = [' '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in test['ingredients']]       \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ingredients_string1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = train['ingredients'].apply(lambda x:','.join(x))\n",
    "ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will create a corpus.\n",
    "corpustr = train['ingredients_string1']\n",
    "corpusts = test['ingredients_string1']\n",
    "corpustr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "#You could develop an understanding based on each.  \n",
    "vectorizertr = TfidfVectorizer(stop_words='english',\n",
    "                             ngram_range = ( 1 , 1 ),analyzer=\"word\", \n",
    "                             max_df = .57 , binary=False , token_pattern=r'\\w+' , sublinear_tf=False)\n",
    "vectorizerts = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that this doesn't work with the #todense option.  \n",
    "tfidftr=vectorizertr.fit_transform(corpustr)\n",
    "predictors_tr = tfidftr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that this doesn't work with the #todense option.  This creates a matrix of predictors from the corpus. \n",
    "tfidfts=vectorizertr.transform(corpusts)\n",
    "predictors_ts= tfidfts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is target variable.  \n",
    "targets_tr = train['cuisine']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression and Regularization.\n",
    "\n",
    "- Regularlization can help us with the large matrix by adding a penalty for each parameter. \n",
    "- Finding out how much regularization via grid search (search across hyperparameters.)\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "```C : float, default: 1.0\n",
    "Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression. \n",
    "parameters = {'C':[1, 10]}\n",
    "#clf = LinearSVC()\n",
    "clf = LogisticRegression()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#This uses that associated paramters to search a grid space. \n",
    "classifier = GridSearchCV(clf, parameters)\n",
    "classifier=classifier.fit(predictors_tr,targets_tr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This predicts the outcome for the test set. \n",
    "predictions=classifier.predict(predictors_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This adds it to the resulting dataframe. \n",
    "test['cuisine'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This creates the submision dataframe\n",
    "submission2=test[['id' ,  'cuisine' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This outputs the file.\n",
    "submission2.to_csv(\"2_logisticSubmission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random forest object which will include all the parameters\n",
    "# for the fit\n",
    "forest = RandomForestClassifier(n_estimators = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the training data to the Survived labels and create the decision trees\n",
    "forest = forest.fit(predictors_tr,targets_tr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the same decision trees and run it on the test data\n",
    "predictions = forest.predict(predictors_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This adds it to the resulting dataframe. \n",
    "test['cuisine'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This creates the submision dataframe\n",
    "submission2=test[['id' ,  'cuisine' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = train['ingredients'].apply(lambda x:','.join(x))\n",
    "ingredients\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What we really need is a ingredient freqency, inverse cuisine frequency.  \n",
    "#Let's first create a function to create a count\n",
    "def tf(count, N):\n",
    "        return count / float(N)\n",
    "\n",
    "#Now let's create a function for IDF....\n",
    "def idf(count, N ):\n",
    "\n",
    "    # tf-idf calc involves multiplying against a tf value less than 0, so it's\n",
    "    # necessary to return a value greater than 1 for consistent scoring. \n",
    "    # (Multiplying two values less than 1 returns a value less than each of \n",
    "    # them.)\n",
    "\n",
    "    try:\n",
    "        return 1.0 + log(float(N) / count)\n",
    "    except ZeroDivisionError:\n",
    "        return 1.0\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "#This creates a Corpus for each incredient\n",
    "corpus=','.join(x.strip() for x in train['ingredients_clean_string1']).split(',')\n",
    "total=Counter(corpus)\n",
    "#This creates a corpus for each word\n",
    "corpus2=','.join(x.strip() for x in train['ingredients_string1']).split(' ')\n",
    "#This just does some extra cleaning....because of some issues with file. \n",
    "corpus3=','.join(x.strip() for x in corpus2).split(',')\n",
    "total2=Counter(corpus3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train))\n",
    "countcuisines=Counter(train['cuisine'])\n",
    "countcuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to create a function that can take in a dictionary [a lookup that has terms and values] and \n",
    "# score different recipes by the lookup.\n",
    "\n",
    "def score(dictionary, stringx, delimiter):\n",
    "    sumt=sum((dictionary.get(x,0) for x in stringx.split(delimiter)))\n",
    "    return  sumt/len(stringx.split(delimiter))\n",
    "\n",
    "#Alt.   \n",
    "#    sumt=0\n",
    "#    for x in stringx.split(delimiter):\n",
    "#        sumt+=dictionary[x]\n",
    "    \n",
    "testdic={'salt': .5, 'vanilla': .2, 'butter': .3,'sugar': .1}\n",
    "teststring='salt,vanilla,sugar,stink'\n",
    "teststring2='salt vanilla sugar butter stink'\n",
    "print(score(testdic,teststring,','))\n",
    "print(score(testdic,teststring2,' '))\n",
    "#print(score(testdic,teststring,' '))\n",
    "print(\"Test1 Value: \", (.5+.2+.1)/4)\n",
    "print(\"Test2 Value: \", (.5+.2+.1+.3)/5)\n",
    "\n",
    "\n",
    "#Now we are using that separate function in another function.  \n",
    "#title_fn = lambda x: 1 if has_title(x) else 0\n",
    "#Finally, we call the function for name\n",
    "#train['Title'] = train['Name'].map(title_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "trainc = pd.DataFrame()\n",
    "trainc2 = pd.DataFrame()\n",
    "testc = pd.DataFrame()\n",
    "testc2 = pd.DataFrame()\n",
    "\n",
    "#This will loop through each unique cuisine\n",
    "for cuisine in train['cuisine'].unique():\n",
    "#This selects only rows that are greek.\n",
    "\n",
    "#Number of rows in the cuisine\n",
    "    cuisinerows=train[train['cuisine'] == cuisine]\n",
    "    notcuisinerows=train[train['cuisine'] != cuisine]\n",
    "    \n",
    "    #print (cuisinerows)\n",
    "    \n",
    "    #','.join(x.strip() for x in line.split(':'))\n",
    "    \n",
    "    #This looks at specific ingredients in the cuisine corpus\n",
    "    cuisinecorpus=','.join(x.strip() for x in cuisinerows['ingredients_clean_string1']).split(',')\n",
    "    #This looks at specific ingredients not in cuisine\n",
    "    notcuisinecorpus=','.join(x.strip() for x in notcuisinerows['ingredients_clean_string1']).split(',')\n",
    "   \n",
    "    #This treats all words individually in cuisine\n",
    "    cuisinecorpus2=','.join(x.strip() for x in cuisinerows['ingredients_string1']).split(' ')\n",
    "    notcuisinecorpus2=','.join(x.strip() for x in notcuisinerows['ingredients_string1']).split(' ')\n",
    "    #this extra line is just some additional cuisine\n",
    "    cuisinecorpus2=','.join(x.strip() for x in cuisinecorpus2).split(',')\n",
    "    notcuisinecorpus2=','.join(x.strip() for x in cuisinecorpus2).split(',')\n",
    "    \n",
    "    #This creates the document term matrix for each.\n",
    "    tfcuisine=Counter(cuisinecorpus)\n",
    "    tfnotcuisine=Counter(notcuisinecorpus)\n",
    "    \n",
    "    tfcuisine2=Counter(cuisinecorpus2)\n",
    "    tfnotcuisine2=Counter(notcuisinecorpus2)\n",
    "     \n",
    "    #We didn't talk about it much in class, but this is creating a dict that indicates TFIDF for each ingredient\n",
    "  \n",
    "    cfincf={k: (tf(tfcuisine[k],len(cuisinecorpus))*idf(tfnotcuisine[k],len(notcuisinecorpus)))  for k in  tfcuisine.keys()}    \n",
    "    \n",
    "    #We didn't talk about it much in class, but this is creating a dict that indicates TFIDF for each word\n",
    "    cfincf2={k: (tf(tfcuisine2[k],len(cuisinecorpus2))*idf(tfnotcuisine2[k],len(notcuisinecorpus2)))  for k in  tfcuisine2.keys()}    \n",
    "    \n",
    "    #Now we will use our strings to score each outcome. \n",
    "    score_fn = lambda x: score(cfincf, x, ',') \n",
    "    score_fn2 = lambda x: score(cfincf2, x, ' ')\n",
    "    \n",
    "#Finally, we call the function for name\n",
    "    trainc[cuisine] = train['ingredients_clean_string1'].map(score_fn)\n",
    "    trainc2[cuisine] = train['ingredients_clean_string1'].map(score_fn2)\n",
    "    testc[cuisine] = test['ingredients_clean_string1'].map(score_fn)\n",
    "    testc2[cuisine] = test['ingredients_clean_string1'].map(score_fn2)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#This creates a prediction from the column that has the maximum value and outputs it to a file. \n",
    "test['cuisine']=testc.idxmax(axis=1)\n",
    "submission=test[['id' ,  'cuisine' ]]\n",
    "submission.to_csv(\"4_tfidf1.csv\",index=False)\n",
    "test['cuisine']=testc2.idxmax(axis=1)\n",
    "submission=test[['id' ,  'cuisine' ]]\n",
    "submission.to_csv(\"5_tfidf2.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainc['prediction']=trainc.idxmax(axis=1)\n",
    "trainc2['prediction']=trainc2.idxmax(axis=1)\n",
    "trainc['cuisine']=train['cuisine']\n",
    "trainc2['cuisine']=train['cuisine']\n",
    "trainc.to_csv(\"coded1.csv\",index=False)\n",
    "trainc2.to_csv(\"coded2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
